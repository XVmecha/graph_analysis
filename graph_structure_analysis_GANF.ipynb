{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc176f11",
   "metadata": {},
   "source": [
    "#### TODO sensor_sims add names\n",
    "#### TODO consistnecy analysis per sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febbedf1a349b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob as glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da4e0cad824932e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:21.472075Z",
     "start_time": "2025-03-24T13:07:21.458929Z"
    }
   },
   "outputs": [],
   "source": [
    "swat_sensors = [\n",
    "    \"Timestamp\", \"FIT101\", \"LIT101\", \"MV101\", \"P101\", \"P102\", \"AIT201\", \"AIT202\",\n",
    "    \"AIT203\", \"FIT201\", \"MV201\", \"P201\", \"P203\", \"P204\", \"P205\", \"P206\",\n",
    "    \"DPIT301\", \"FIT301\", \"LIT301\", \"MV301\", \"MV302\", \"MV303\", \"MV304\",\n",
    "    \"P302\", \"AIT401\", \"AIT402\", \"FIT401\", \"LIT401\", \"P402\", \"P403\",\n",
    "    \"UV401\", \"AIT501\", \"AIT502\", \"AIT503\", \"AIT504\", \"FIT501\", \"FIT502\", \"FIT503\",\n",
    "    \"FIT504\", \"P501\", \"PIT501\", \"PIT502\", \"PIT503\", \"FIT601\",\n",
    "    \"P602\", \"Normal/Attack\"\n",
    "]\n",
    "\n",
    "# Dictionary with continuous index as key and [sensor_name, type, group] as value\n",
    "swat_sensors_dict = {\n",
    "    0: [\"FIT101\", \"Sensor\", 1],\n",
    "    1: [\"LIT101\", \"Sensor\", 1],\n",
    "    2: [\"MV101\", \"Actuator\", 1],\n",
    "    3: [\"P101\", \"Actuator\", 1],\n",
    "    4: [\"P102\", \"Actuator\", 1],\n",
    "    5: [\"AIT201\", \"Sensor\", 2],\n",
    "    6: [\"AIT202\", \"Sensor\", 2],\n",
    "    7: [\"AIT203\", \"Sensor\", 2],\n",
    "    8: [\"FIT201\", \"Sensor\", 2],\n",
    "    9: [\"MV201\", \"Actuator\", 2],\n",
    "    10: [\"P201\", \"Actuator\", 2],\n",
    "    11: [\"P203\", \"Actuator\", 2],\n",
    "    12: [\"P204\", \"Actuator\", 2],\n",
    "    13: [\"P205\", \"Actuator\", 2],\n",
    "    14: [\"P206\", \"Actuator\", 2],\n",
    "    15: [\"DPIT301\", \"Sensor\", 3],\n",
    "    16: [\"FIT301\", \"Sensor\", 3],\n",
    "    17: [\"LIT301\", \"Sensor\", 3],\n",
    "    18: [\"MV301\", \"Actuator\", 3],\n",
    "    19: [\"MV302\", \"Actuator\", 3],\n",
    "    20: [\"MV303\", \"Actuator\", 3],\n",
    "    21: [\"MV304\", \"Actuator\", 3],\n",
    "    22: [\"P302\", \"Actuator\", 3],\n",
    "    23: [\"AIT401\", \"Sensor\", 4],\n",
    "    24: [\"AIT402\", \"Sensor\", 4],\n",
    "    25: [\"FIT401\", \"Sensor\", 4],\n",
    "    26: [\"LIT401\", \"Actuator\", 4],\n",
    "    27: [\"P402\", \"Actuator\", 4],\n",
    "    28: [\"P403\", \"Actuator\", 4],\n",
    "    29: [\"UV401\", \"Actuator\", 4],\n",
    "    30: [\"AIT501\", \"Sensor\", 5],\n",
    "    31: [\"AIT502\", \"Sensor\", 5],\n",
    "    32: [\"AIT503\", \"Sensor\", 5],\n",
    "    33: [\"AIT504\", \"Sensor\", 5],\n",
    "    34: [\"FIT501\", \"Sensor\", 5],\n",
    "    35: [\"FIT502\", \"Sensor\", 5],\n",
    "    36: [\"FIT503\", \"Sensor\", 5],\n",
    "    37: [\"FIT504\", \"Sensor\", 5],\n",
    "    38: [\"P501\", \"Actuator\", 5],\n",
    "    39: [\"PIT501\", \"Sensor\", 5],\n",
    "    40: [\"PIT502\", \"Sensor\", 5],\n",
    "    41: [\"PIT503\", \"Sensor\", 5],\n",
    "    42: [\"FIT601\", \"Sensor\", 6],\n",
    "    43: [\"P602\", \"Actuator\", 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d02de",
   "metadata": {},
   "source": [
    "### Data sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170cf4aabb9629ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:11:58.568345Z",
     "start_time": "2025-03-24T12:11:58.563361Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dc5eda8ddc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No matrices found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearned_graph_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mswat_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-dc5eda8ddc01>\u001b[0m in \u001b[0;36mbuild_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Find all matching files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfile_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(file_paths)} files matching the pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "def build_tensor():\n",
    "    # Expand the tilde to the home directory\n",
    "    pattern = os.path.expanduser(f\"~/baselines/GANF/checkpoint/model/GANF_water_seed_18/graph_best*.pt\")\n",
    "\n",
    "    # Find all matching files\n",
    "    file_paths = sorted(glob(pattern))\n",
    "    print(f\"Found {len(file_paths)} files matching the pattern\")\n",
    "\n",
    "    # Function to load a matrix from a text file\n",
    "    def load_matrix(file_path):\n",
    "        return torch.load(file_path)\n",
    "\n",
    "\n",
    "    # Load all matrices into a tensor\n",
    "    matrices = []\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        matrix = load_matrix(file_path)\n",
    "        matrix = matrix.cpu().numpy()\n",
    "        matrices.append(matrix)\n",
    "        print(f\"Loaded matrix with shape {matrix.shape}\")\n",
    "\n",
    "    # Stack all matrices into a single tensor\n",
    "    if matrices:\n",
    "        learned_graph_tensor = np.stack(matrices)\n",
    "        print(f\"Created tensor with shape {learned_graph_tensor.shape}\")\n",
    "    else:\n",
    "        print(\"No matrices found\")\n",
    "    return learned_graph_tensor\n",
    "swat_tensor = build_tensor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ff518bcc36cef",
   "metadata": {},
   "source": [
    "### node influence distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74433ce0dd398f76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T12:13:54.660922Z",
     "start_time": "2025-03-24T12:13:54.648733Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def analyze_node_connectivity(matrices, analysis=True):\n",
    "    # Load all matching matrices\n",
    "    results = []\n",
    "\n",
    "    for matrix in matrices:\n",
    "        # Calculate degree for each node\n",
    "        node_degrees = np.sum(matrix, axis=1)\n",
    "\n",
    "        # Calculate statistics\n",
    "        degree_mean = np.mean(node_degrees)\n",
    "        degree_std = np.std(node_degrees)\n",
    "        degree_variance = np.var(node_degrees)\n",
    "\n",
    "        # Get highest and lowest connected nodes\n",
    "        most_connected = np.argmax(node_degrees)\n",
    "        least_connected = np.argmin(node_degrees)\n",
    "\n",
    "        results.append({\n",
    "            'degree_mean': degree_mean,\n",
    "            'degree_std': degree_std,\n",
    "            'degree_variance': degree_variance,\n",
    "            'most_connected': (most_connected, node_degrees[most_connected]),\n",
    "            'least_connected': (least_connected, node_degrees[least_connected])\n",
    "        })\n",
    "\n",
    "        print(f\"Mean node degree: {degree_mean:.4f}\")\n",
    "        print(f\"Std of degrees: {degree_std:.4f}\")\n",
    "        print(f\"Variance of degrees: {degree_variance:.4f}\")\n",
    "        print(f\"Most connected node: {most_connected} (degree: {node_degrees[most_connected]:.4f})\")\n",
    "        print(f\"Least connected node: {least_connected} (degree: {node_degrees[least_connected]:.4f})\")\n",
    "\n",
    "        # Calculate overall statistics across all matrices\n",
    "    if analysis:\n",
    "        means = np.array([result['degree_mean'] for result in results])\n",
    "        stds = np.array([result['degree_std'] for result in results])\n",
    "        variances = np.array([result['degree_variance'] for result in results])\n",
    "\n",
    "        print(\"\\nOverall Statistics:\")\n",
    "        print(f\"Mean of means: {np.mean(means):.4f} ± {np.std(means):.4f}\")\n",
    "        print(f\"Mean of std devs: {np.mean(stds):.4f} ± {np.std(stds):.4f}\")\n",
    "        print(f\"Mean of variances: {np.mean(variances):.4f} ± {np.std(variances):.4f}\")\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75749640a510e0e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:24:35.210883Z",
     "start_time": "2025-03-24T10:24:35.206769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean node degree: 1.2021\n",
      "Std of degrees: 0.6502\n",
      "Variance of degrees: 0.4228\n",
      "Most connected node: 30 (degree: 2.9280)\n",
      "Least connected node: 18 (degree: 0.0261)\n",
      "Mean node degree: 0.7609\n",
      "Std of degrees: 0.2864\n",
      "Variance of degrees: 0.0820\n",
      "Most connected node: 25 (degree: 1.3996)\n",
      "Least connected node: 18 (degree: 0.1197)\n",
      "\n",
      "Overall Statistics:\n",
      "Mean of means: 0.9815 ± 0.2206\n",
      "Mean of std devs: 0.4683 ± 0.1819\n",
      "Mean of variances: 0.2524 ± 0.1704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'degree_mean': np.float32(1.2020801),\n",
       "  'degree_std': np.float32(0.6502452),\n",
       "  'degree_variance': np.float32(0.42281878),\n",
       "  'most_connected': (np.int64(30), np.float32(2.9280012)),\n",
       "  'least_connected': (np.int64(18), np.float32(0.02614277))},\n",
       " {'degree_mean': np.float32(0.76089805),\n",
       "  'degree_std': np.float32(0.28642446),\n",
       "  'degree_variance': np.float32(0.08203897),\n",
       "  'most_connected': (np.int64(25), np.float32(1.3996139)),\n",
       "  'least_connected': (np.int64(18), np.float32(0.11967802))}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_node_connectivity(swat_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f831c69661a15e9",
   "metadata": {},
   "source": [
    "### structural convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d667166dc6685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:42:20.689242Z",
     "start_time": "2025-03-24T10:42:20.677953Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarities(matrices):\n",
    "    # Calculate cosine similarities between all pairs of matrices\n",
    "    num_matrices = len(matrices)\n",
    "    all_similarities = []\n",
    "\n",
    "    for i in range(num_matrices):\n",
    "        for j in range(i+1, num_matrices):\n",
    "            # Flatten matrices for cosine similarity calculation\n",
    "            matrix_i_flat = matrices[i].reshape(1, -1)\n",
    "            matrix_j_flat = matrices[j].reshape(1, -1)\n",
    "\n",
    "            sim = cosine_similarity(matrix_i_flat, matrix_j_flat)[0, 0]\n",
    "            all_similarities.append(sim)\n",
    "            print(f\"Cosine similarity between matrix {i} and {j}: {sim:.4f}\")\n",
    "\n",
    "    # Calculate average similarity\n",
    "    avg_similarity = np.mean(all_similarities) if all_similarities else None\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    # Calculate cosine similarity for each sensor (row in the matrix)\n",
    "    sensor_similarities = []\n",
    "\n",
    "    # Check if matrices have the same shape\n",
    "    if all(m.shape == matrices[0].shape for m in matrices):\n",
    "        num_sensors = matrices[0].shape[0]\n",
    "        for sensor_idx in range(num_sensors):\n",
    "            sensor_sims = []\n",
    "            for i in range(num_matrices):\n",
    "                for j in range(i+1, num_matrices):\n",
    "                    # Get the row for this sensor from both matrices\n",
    "                    sensor_i = matrices[i][sensor_idx, :].reshape(1, -1)\n",
    "                    sensor_j = matrices[j][sensor_idx, :].reshape(1, -1)\n",
    "\n",
    "                    sim = cosine_similarity(sensor_i, sensor_j)[0, 0]\n",
    "                    sensor_sims.append(sim)\n",
    "\n",
    "            # Average similarity for this sensor\n",
    "            avg_sensor_sim = np.mean(sensor_sims) if sensor_sims else None\n",
    "            sensor_similarities.append(avg_sensor_sim)\n",
    "            print(f\"Sensor {swat_sensors_dict[sensor_idx][0]} average similarity: {avg_sensor_sim:.4f}\")\n",
    "    else:\n",
    "        print(\"Cannot calculate per-sensor similarities: matrices have different shapes\")\n",
    "    # all matrix similarities, average sim of all matrices, similarity per sensor for all matrices,\n",
    "    return all_similarities, avg_similarity, sensor_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbf492a05cd93e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:42:21.218951Z",
     "start_time": "2025-03-24T10:42:21.196164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between matrix 0 and 1: 0.6794\n",
      "Average cosine similarity: 0.6794\n",
      "Sensor 0 average similarity: 0.8354\n",
      "Sensor 1 average similarity: 0.5595\n",
      "Sensor 2 average similarity: 0.7810\n",
      "Sensor 3 average similarity: 0.8837\n",
      "Sensor 4 average similarity: 0.6121\n",
      "Sensor 5 average similarity: 0.7765\n",
      "Sensor 6 average similarity: 0.4251\n",
      "Sensor 7 average similarity: 0.7043\n",
      "Sensor 8 average similarity: 0.7888\n",
      "Sensor 9 average similarity: 0.8648\n",
      "Sensor 10 average similarity: 0.6383\n",
      "Sensor 11 average similarity: 0.8255\n",
      "Sensor 12 average similarity: 0.4446\n",
      "Sensor 13 average similarity: 0.8492\n",
      "Sensor 14 average similarity: 0.3963\n",
      "Sensor 15 average similarity: 0.7307\n",
      "Sensor 16 average similarity: 0.8192\n",
      "Sensor 17 average similarity: 0.6078\n",
      "Sensor 18 average similarity: 0.3906\n",
      "Sensor 19 average similarity: 0.8495\n",
      "Sensor 20 average similarity: 0.8508\n",
      "Sensor 21 average similarity: 0.6776\n",
      "Sensor 22 average similarity: 0.7595\n",
      "Sensor 23 average similarity: 0.7122\n",
      "Sensor 24 average similarity: 0.4741\n",
      "Sensor 25 average similarity: 0.8171\n",
      "Sensor 26 average similarity: 0.7733\n",
      "Sensor 27 average similarity: 0.7202\n",
      "Sensor 28 average similarity: 0.6610\n",
      "Sensor 29 average similarity: 0.5620\n",
      "Sensor 30 average similarity: 0.6468\n",
      "Sensor 31 average similarity: 0.0419\n",
      "Sensor 32 average similarity: 0.3633\n",
      "Sensor 33 average similarity: 0.3193\n",
      "Sensor 34 average similarity: 0.7048\n",
      "Sensor 35 average similarity: 0.7049\n",
      "Sensor 36 average similarity: 0.9029\n",
      "Sensor 37 average similarity: 0.8004\n",
      "Sensor 38 average similarity: 0.7033\n",
      "Sensor 39 average similarity: 0.7800\n",
      "Sensor 40 average similarity: 0.5418\n",
      "Sensor 41 average similarity: 0.7295\n",
      "Sensor 42 average similarity: 0.8003\n",
      "Sensor 43 average similarity: 0.8708\n"
     ]
    }
   ],
   "source": [
    "all_sims, avg_sim, sensor_sims = calculate_cosine_similarities(swat_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c92521784f1a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:42:43.880628Z",
     "start_time": "2025-03-24T10:42:43.876948Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1c6dab22d7483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a6bf2b5caa0855d",
   "metadata": {},
   "source": [
    "### homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1e6cb09fcfc0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:11:17.575868Z",
     "start_time": "2025-03-24T13:11:17.562353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted homophily (type 1): 0.4857\n",
      "Total weighted edges: 26.4457\n",
      "Same-attribute weighted edges: 12.8459\n",
      "Weighted homophily (type 1): 0.5010\n",
      "Total weighted edges: 16.7396\n",
      "Same-attribute weighted edges: 8.3871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float32(0.48574436), np.float32(0.50103366)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_weighted_homophily(tensor,sensor_dictionary,type=1):\n",
    "    num_matrices = len(tensor)\n",
    "    homophily_values = []\n",
    "\n",
    "    for i in range(len(tensor)):\n",
    "            # Load the adjacency matrix\n",
    "            adj_matrix = tensor[i]\n",
    "\n",
    "            # Ensure the matrix is symmetric (in case it's not)\n",
    "            adj_matrix = (adj_matrix + adj_matrix.T) / 2\n",
    "\n",
    "            # Initialize counters\n",
    "            weighted_total = 0\n",
    "            weighted_same_attribute = 0\n",
    "\n",
    "            # Iterate through all node pairs (only upper triangle to avoid double counting)\n",
    "            for i in range(len(adj_matrix)):\n",
    "                attr_i = sensor_dictionary[i][type]\n",
    "\n",
    "                for j in range(i+1, len(adj_matrix)):  # upper triangle only\n",
    "                    attr_j = sensor_dictionary[j][type]\n",
    "\n",
    "                    # Weight of the edge between nodes i and j\n",
    "                    weight = adj_matrix[i, j]\n",
    "\n",
    "                    # Add to total weighted edges\n",
    "                    weighted_total += weight\n",
    "\n",
    "                    # If attributes match, add to same-attribute counter\n",
    "                    if attr_i == attr_j:\n",
    "                        weighted_same_attribute += weight\n",
    "\n",
    "            # Calculate homophily for this matrix\n",
    "            homophily = weighted_same_attribute / weighted_total if weighted_total > 0 else 0\n",
    "            homophily_values.append(homophily)\n",
    "\n",
    "            print(f\"Weighted homophily (type {type}): {homophily:.4f}\")\n",
    "            print(f\"Total weighted edges: {weighted_total:.4f}\")\n",
    "            print(f\"Same-attribute weighted edges: {weighted_same_attribute:.4f}\")\n",
    "\n",
    "    return homophily_values\n",
    "calculate_weighted_homophily(swat_tensor,swat_sensors_dict,type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf2ba1a1960d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:51.226012Z",
     "start_time": "2025-03-24T13:07:51.223182Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eaa06f697d2022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:08:02.337914Z",
     "start_time": "2025-03-24T13:08:02.329200Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdn_solo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
